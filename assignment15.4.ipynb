{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a09ad28-aa56-498d-85e9-ae868093dbec",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efecdf85-829c-4635-ac91-e9c00f6ac6de",
   "metadata": {},
   "source": [
    "A1.\n",
    "- Lasso Regression (Least Absolute Shrinkage and Selection Operator) is a linear regression technique that adds a regularization term to the loss function, which is the sum of the absolute values of coefficients (L1 regularization).\n",
    "- Lasso differs from other regression techniques, such as ordinary least squares (OLS) regression, Ridge Regression, and Elastic Net, in that it can perform feature selection by setting some coefficients to exactly zero.\n",
    "- Unlike Ridge, which uses L2 regularization, Lasso tends to create sparse models with a subset of important features retained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b588ada-b7a5-4c1b-b40a-7d8c3017ccb5",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dfb184-1aa4-43be-864f-4bfc951f9f2f",
   "metadata": {},
   "source": [
    "A2.\n",
    "- The main advantage of Lasso Regression for feature selection is its ability to automatically select a subset of relevant features.\n",
    "- Lasso can set the coefficients of less important features to zero, effectively removing them from the model.\n",
    "- This simplifies the model, improves interpretability, and potentially leads to better generalization when dealing with high-dimensional datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ad53f-ce21-448c-9129-706bf18a4bee",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee02735-c322-4c58-ab23-5353dcd9883a",
   "metadata": {},
   "source": [
    "A3.\n",
    "- Interpreting Lasso coefficients is similar to interpreting coefficients in ordinary linear regression.\n",
    "- The coefficients represent the change in the dependent variable for a one-unit change in the corresponding independent variable while holding all other variables constant.\n",
    "- In Lasso, some coefficients may be exactly zero, indicating that the corresponding features are not included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a1c20-1b9d-4e6e-90ba-163ca9654c36",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabeac8-3c5e-41dd-91f8-225e4fe2248d",
   "metadata": {},
   "source": [
    "A4.\n",
    "- The primary tuning parameter in Lasso Regression is lambda (λ), also known as the regularization parameter.\n",
    "- Lambda controls the strength of the L1 regularization. Larger values of λ result in stronger regularization and more coefficients being set to zero.\n",
    "- Another related parameter is alpha (α), which controls the mix between L1 and L2 regularization. When α = 1, it's pure Lasso; when α = 0, it's pure Ridge (Elastic Net combines both).\n",
    "- The choice of λ and α can significantly affect the model's performance, and they are typically determined through cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7c03a-9fb4-4ddb-9cd4-f769ccdf98bd",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26329b75-5863-4ff1-aaf8-402bda1af60a",
   "metadata": {},
   "source": [
    "A5.\n",
    "- Lasso Regression is inherently a linear model. It can handle non-linear problems to some extent by transforming the input features or by incorporating non-linear transformations (e.g., polynomial features) into the model.\n",
    "- However, for highly non-linear problems, other non-linear regression techniques like decision trees, support vector machines, or neural networks may be more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6c9bf9-d275-499d-b471-c2efd6e28b57",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6c4e9-194b-4a0f-8c83-48bbe6ef45cd",
   "metadata": {},
   "source": [
    "A6.\n",
    "- The primary difference between Ridge and Lasso Regression is the type of regularization used.\n",
    "- Ridge uses L2 regularization, adding a penalty term proportional to the sum of squared coefficients. It shrinks coefficients towards zero but does not set them exactly to zero.\n",
    "- Lasso uses L1 regularization, adding a penalty term proportional to the sum of absolute values of coefficients. It can set coefficients to exactly zero, performing feature selection.\n",
    "- Ridge tends to distribute the reduction in coefficients evenly, while Lasso can create a sparse model with some coefficients eliminated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ea1ac-1abe-4c76-ae2d-23135e383ea5",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a8f064-9dbd-49a7-9e0b-4c702503f5f1",
   "metadata": {},
   "source": [
    "A7.\n",
    "- Lasso Regression is effective at handling multicollinearity (high correlation between independent variables).\n",
    "- It can set some of the correlated variables' coefficients to zero, effectively choosing one from the group while reducing the impact of multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f766b9-7abf-48e9-90f0-8027d19a0e39",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5682698e-1005-4dd8-bc77-ab5625add3e5",
   "metadata": {},
   "source": [
    "A8.\n",
    "- The optimal λ value in Lasso Regression is typically determined through cross-validation.\n",
    "- You train the Lasso model with various values of λ and use cross-validation to assess the model's performance (e.g., using mean squared error) on a validation set.\n",
    "- The λ value that minimizes the validation error is chosen as the optimal regularization strength, striking a balance between model complexity and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0a245-b870-4139-8f4a-3b9a2c141b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
