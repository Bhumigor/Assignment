{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d346e2-3fac-419b-81e2-e3624c0fa65c",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be5039-1ca9-412b-80dd-7d54e32852c1",
   "metadata": {},
   "source": [
    "A1. Anomaly detection is the process of identifying data points, events, or observations that deviate significantly from the majority of the data, which are considered normal. These deviations are called anomalies, outliers, or exceptions. The purpose of anomaly detection is to identify rare items, events, or observations that raise suspicions by differing significantly from the majority of the data. This can be crucial in various applications such as fraud detection, network security, fault detection, system health monitoring, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f177119b-c12e-4c6e-874e-a4e661e99da8",
   "metadata": {},
   "source": [
    "Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29c271-1ddd-45d1-ae11-813515d14b77",
   "metadata": {},
   "source": [
    "A2. Key challenges in anomaly detection include:\n",
    "\n",
    "    Imbalanced Data: Anomalies are rare compared to normal instances, leading to highly imbalanced datasets.\n",
    "    Variety of Anomalies: Anomalies can vary greatly and may not follow a single pattern.\n",
    "    High Dimensionality: In high-dimensional data, the concept of distance and density can become less meaningful.\n",
    "    Noise: Distinguishing between noise and actual anomalies can be difficult.\n",
    "    Dynamic Data: In many applications, data distributions can change over time, making it hard to maintain accurate models.\n",
    "    Scalability: Efficiently processing and analyzing large volumes of data is challenging.\n",
    "    Label Availability: Often, there are few or no labeled examples of anomalies, complicating supervised learning approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b05588-8881-4275-ad55-d33c72048450",
   "metadata": {},
   "source": [
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff42d1d-f9de-453a-ac1c-0b434d7b5941",
   "metadata": {},
   "source": [
    "A3. Unsupervised anomaly detection:\n",
    "\n",
    "    Data: Does not require labeled data. It assumes that anomalies are rare and different from the majority of the data.\n",
    "    Approach: Uses methods like clustering, density estimation, and distance-based techniques to identify points that do not fit the general pattern of the data.\n",
    "\n",
    "Supervised anomaly detection:\n",
    "\n",
    "    Data: Requires labeled data with examples of both normal and anomalous instances.\n",
    "    Approach: Uses classification algorithms to learn the boundary between normal and anomalous classes from the labeled data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a389c8fd-1e69-4821-a51e-8b691bf1f16d",
   "metadata": {},
   "source": [
    "Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2706c-6319-4ab8-8061-3c36c384e38e",
   "metadata": {},
   "source": [
    "A4. Main categories of anomaly detection algorithms include:\n",
    "\n",
    "1. Statistical Methods: Assume a statistical model for the data and detect anomalies based on deviations from this model.\n",
    "    - Example: Z-score, Gaussian mixture models.\n",
    "2. Proximity-Based Methods: Detect anomalies based on their distance or density relative to other points.\n",
    "    - Example: k-Nearest Neighbors (k-NN), Local Outlier Factor (LOF).\n",
    "3. Clustering-Based Methods: Identify anomalies as points that do not belong to any cluster or belong to small/sparse clusters.\n",
    "    - Example: DBSCAN, k-means clustering.\n",
    "4. Machine Learning Methods: Use machine learning algorithms to learn normal patterns and identify deviations.\n",
    "    - Example: Isolation Forest, Autoencoders.\n",
    "5. Information-Theoretic Methods: Use metrics like entropy to detect anomalies.\n",
    "    - Example: Anomaly detection using Minimum Description Length (MDL)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc46aa-7bb3-4c13-b455-902711bbdc54",
   "metadata": {},
   "source": [
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbf838-19b1-416a-a536-0aa09c746600",
   "metadata": {},
   "source": [
    "A5. Main assumptions of distance-based anomaly detection methods:\n",
    "\n",
    "    - Normal Points are Close: Normal data points are assumed to be close to each other.\n",
    "    - Anomalous Points are Distant: Anomalies are far from the majority of the data points.\n",
    "    - Data Density: Anomalies occur in low-density regions compared to normal points, which are in high-density regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d757b5-ff84-4e30-8f80-6e0faaf11d52",
   "metadata": {},
   "source": [
    "Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c24dcd-8b9f-494b-a6b1-627eb136f9f6",
   "metadata": {},
   "source": [
    "A6. The Local Outlier Factor (LOF) algorithm computes anomaly scores based on the local density deviation of a data point with respect to its neighbors. The steps involved are:\n",
    "\n",
    "- k-Distance: Compute the distance to the k-th nearest neighbor.\n",
    "- Reachability Distance: Define the reachability distance of a point p with respect to another point o as the maximum of the k-distance of o and the distance between p and o.\n",
    "- Local Reachability Density (LRD): Compute the LRD of a point as the inverse of the average reachability distance of the point from its k nearest neighbors.\n",
    "- LOF Score: The LOF score of a point is the average ratio of the LRD of its k nearest neighbors to its own LRD.\n",
    "\n",
    "A higher LOF score indicates that the point is more likely to be an outlier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f4b33-23f9-4959-b83a-c27260ee74a5",
   "metadata": {},
   "source": [
    "Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae568f8-8e9e-4c64-b5a7-40bfe10fbab3",
   "metadata": {},
   "source": [
    "A7. Key parameters of the Isolation Forest algorithm include:\n",
    "\n",
    "- n_estimators: The number of trees in the forest.\n",
    "- max_samples: The number of samples to draw from the dataset to train each tree.\n",
    "- contamination: The proportion of outliers in the dataset. It is used to set the threshold on the decision function.\n",
    "- max_features: The number of features to draw from the dataset to train each tree.\n",
    "- bootstrap: Whether samples are drawn with replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183ef5f-cca9-42ff-b355-fb664877b91a",
   "metadata": {},
   "source": [
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8059930-35f0-4b17-8ec8-b5a34a4fcf2b",
   "metadata": {},
   "source": [
    "A8. If a data point has only 2 neighbors of the same class within a radius of 0.5 using KNN with K=10, it indicates that this point is relatively isolated compared to the majority of the data points. The anomaly score in KNN-based methods often considers the number of neighbors within a certain radius.\n",
    "\n",
    "If we define the anomaly score as:\n",
    "\n",
    "    Anomaly Score = 1-(no. of neighbors of the same class within radius/K)\n",
    "    \n",
    "    then:\n",
    "    Anomaly Score = 1-(2/10) = 1-0.2=0.8\n",
    "\n",
    "A higher anomaly score (closer to 1) indicates a more anomalous point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d95ae-6b9d-4d15-8b1e-647285ec8736",
   "metadata": {},
   "source": [
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55236483-7ea7-4db4-b55d-3bb9b08bb365",
   "metadata": {},
   "source": [
    "A9. The anomaly score in the Isolation Forest algorithm is calculated based on the average path length of a data point across the trees in the forest. The shorter the path length, the more likely the point is an anomaly.\n",
    "\n",
    "The expected average path length c(n) for a dataset of size n is given by:\n",
    "\n",
    "    c(n) = 2H(n-1)-(2(n-1)/n)\n",
    "    \n",
    "where H(i) is the harmonic number and can be approximated by ln(i)+0.5772156649 (Euler-Mascheroni constant)\n",
    "\n",
    "for n = 3000:\n",
    "\n",
    "    H(2999) = ln(2999)+0.5772156649 = 8.006+0.5772156649 = 8.583\n",
    "\n",
    "    C(3000) = 2*8.583 - (2*2999/3000) = 17.166 - 1.999 = 15.167\n",
    "\n",
    "The anomaly score s for a point with an average path length l is calculated as:\n",
    "\n",
    "    s = 2^(-l/c(n))\n",
    "    \n",
    "for l=5.0 and c(3000)=15.167\n",
    "\n",
    "    s = 2^(-5.0/15.167) = 2^(-0.3296) = 0.795\n",
    "    \n",
    "An anomaly score close to 1 indicates a high likelihood of being an anomaly, while a score close to 0 indicates normality. In this case, a score of approximately 0.793 suggests that the data point is relatively anomalous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425a7666-1b11-4de0-b803-2730e7f4e118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
